#!/usr/bin/env python3
"""
Fix Empty URLs - Prof de Basse V3.0.2
RÃ©pare les URLs vides dans search-index-compatible.json
"""

import json
import urllib.parse
from pathlib import Path

BASE_URL = 'https://11drumboy11.github.io/Prof-de-basse-V2/'
BASE_PATH = 'Base de connaissances/Base de connaissances/'

def build_url(path):
    """Construit une URL complÃ¨te et valide"""
    if not path:
        return ''
    
    # Construire le chemin complet
    full_path = BASE_PATH + path
    
    # Encoder chaque partie du chemin
    parts = full_path.split('/')
    encoded_parts = [urllib.parse.quote(part, safe='') for part in parts]
    
    # Construire l'URL finale
    url = BASE_URL + '/'.join(encoded_parts)
    
    return url

def fix_urls(input_file='search-index-compatible.json', output_file='megasearch.json'):
    """RÃ©pare les URLs dans le fichier JSON"""
    
    print("ğŸ”§ RÃ©paration des URLs vides...")
    print(f"ğŸ“‚ Lecture de {input_file}...")
    
    # Charger le fichier
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ Fichier {input_file} introuvable")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur JSON: {e}")
        return False
    
    # Extraire les ressources
    resources = data.get('resources', [])
    print(f"ğŸ“Š {len(resources)} ressources trouvÃ©es")
    
    # Compteurs
    fixed = 0
    already_ok = 0
    no_path = 0
    
    # RÃ©parer chaque ressource
    print("\nğŸ”„ RÃ©paration en cours...")
    for resource in resources:
        url = resource.get('url', '')
        path = resource.get('path', '') or resource.get('filename', '')
        
        if not path:
            no_path += 1
            continue
        
        if url and url.strip():
            already_ok += 1
            continue
        
        # GÃ©nÃ©rer l'URL
        new_url = build_url(path)
        resource['url'] = new_url
        fixed += 1
        
        if fixed <= 3:
            print(f"   âœ… [{fixed}] {resource.get('title', 'Sans titre')[:40]}")
            print(f"       Path: {path}")
            print(f"       URL:  {new_url[:80]}...")
    
    print(f"\nğŸ“Š RÃ©sultats:")
    print(f"   âœ… RÃ©parÃ©es    : {fixed}")
    print(f"   â„¹ï¸  DÃ©jÃ  OK     : {already_ok}")
    print(f"   âš ï¸  Sans path  : {no_path}")
    
    # Sauvegarder
    print(f"\nğŸ’¾ Sauvegarde dans {output_file}...")
    
    if 'metadata' not in data:
        data['metadata'] = {}
    
    if 'stats' not in data['metadata']:
        data['metadata']['stats'] = {}
    
    data['metadata']['stats']['total_resources'] = len(resources)
    data['metadata']['stats']['urls_fixed'] = fixed
    data['metadata']['version'] = '3.0.2'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    file_size = Path(output_file).stat().st_size / 1024
    print(f"âœ… Fichier sauvegardÃ©: {file_size:.1f} KB")
    
    print(f"\nğŸ” VÃ©rification Ã©chantillon:")
    for i in range(min(3, len(resources))):
        resource = resources[i]
        url = resource.get('url', '')
        title = resource.get('title', 'Sans titre')[:40]
        
        if url.startswith('https://'):
            print(f"   âœ… [{i+1}] URL valide - {title}")
        else:
            print(f"   âŒ [{i+1}] URL invalide - {title}")
    
    print("\nğŸ‰ RÃ‰PARATION TERMINÃ‰E !")
    return True

if __name__ == '__main__':
    import sys
    
    input_file = sys.argv[1] if len(sys.argv) > 1 else 'search-index-compatible.json'
    output_file = sys.argv[2] if len(sys.argv) > 2 else 'megasearch.json'
    
    success = fix_urls(input_file, output_file)
    sys.exit(0 if success else 1)
